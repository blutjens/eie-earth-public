{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./pretrained/Pix2pix-CycleGAN/flood_segmentation/scratch_1024_plus/\t[default: ./checkpoints]\n",
      "                crop_size: 1024                          \t[default: 256]\n",
      "                 dataroot: results/flood_color/          \t[default: None]\n",
      "             dataset_mode: single                        \t[default: aligned]\n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "               isFineTune: False                         \t[default: None]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 1024                          \t[default: 256]\n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: .                             \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: True                          \t[default: False]\n",
      "                     norm: batch                         \n",
      "                 num_test: 775                           \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: conditional_binary            \t[default: test]\n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./temp/flood_color/           \t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./pretrained/Pix2pix-CycleGAN/flood_segmentation/scratch_1024_plus/./latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./temp/flood_color/./conditional_binary_latest\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"src/models/Pix2pix-CycleGAN/test.py\", line 64, in <module>\n",
      "    model.test()           # run inference\n",
      "  File \"/home/jupyter/eie_vision/src/models/Pix2pix-CycleGAN/models/base_model.py\", line 115, in test\n",
      "    self.forward()\n",
      "  File \"/home/jupyter/eie_vision/src/models/Pix2pix-CycleGAN/models/pix2pix_model.py\", line 118, in forward\n",
      "    self.fake_B = self.netG(self.real_A)  # G(A)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/jupyter/eie_vision/src/models/Pix2pix-CycleGAN/models/networks.py\", line 465, in forward\n",
      "    return self.model(input)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/jupyter/eie_vision/src/models/Pix2pix-CycleGAN/models/networks.py\", line 533, in forward\n",
      "    return self.model(x)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/jupyter/eie_vision/src/models/Pix2pix-CycleGAN/models/networks.py\", line 535, in forward\n",
      "    return torch.cat([x, self.model(x)], 1)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/activation.py\", line 559, in forward\n",
      "    return F.leaky_relu(input, self.negative_slope, self.inplace)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\", line 1061, in leaky_relu\n",
      "    result = torch._C._nn.leaky_relu_(input, negative_slope)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#Create flood masks for color baseline\n",
    "\n",
    "#Create Segmentation Masks\n",
    "#Generate masks for all of the data generated by pix2pixHD_baseline\n",
    "! cd ../.. ; python src/models/Pix2pix-CycleGAN/test.py --phase 'conditional_binary' --dataroot results/flood_color/ --direction AtoB --results_dir ./temp/flood_color/ --dataset_mode single --model pix2pix --checkpoints_dir ./pretrained/Pix2pix-CycleGAN/flood_segmentation/scratch_1024_plus/ --name . --num_test 775 --no_flip --gpu_ids -1 --batch_size 1  --load_size 1024 --crop_size 1024\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
