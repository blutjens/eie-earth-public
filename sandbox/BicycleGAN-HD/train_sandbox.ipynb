{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for developments of BicycleGAN-HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../.. ; python src/models/BicycleGAN-HD/train.py --continue_train --epoch_count 4 --save_epoch_freq 25 --ngf 48 --model bicycle_gan_hd --lambda_kl 1 --checkpoints_dir temp/checkpoint/BicycleGAN-HD/ --name trial_0 --gpu_ids 6,7 --direction APtoBP --dataset_mode physics_aligned_bin --dataroot ./xBD/ --niter 100 --niter_decay 100 --display_id -1 --load_size 1024 --crop_size 1024 --batch_size 2 --dataroot_A_masks ./xBD/train_mask --dataroot_B_masks ./xBD/train_mask --netD basic_1024_multi --netD2 basic_1024_multi --netG global --netE resnet_1024 --conditional_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 2                             \n",
      "              center_crop: False                         \n",
      "          checkpoints_dir: temp/checkpoint/BicycleGAN-HD/\t[default: ./checkpoints]\n",
      "            conditional_D: True                          \t[default: False]\n",
      "                crop_size: 1024                          \t[default: 256]\n",
      "                 dataroot: ./xBD/                        \t[default: None]\n",
      "         dataroot_A_masks: ./xBD/test_mask               \t[default: ./xBD/bigtiles/masks_v1]\n",
      "         dataroot_B_masks: ./xBD/test_mask               \t[default: ./xBD/bigtiles/masks_v1]\n",
      "             dataset_mode: physics_aligned_bin           \n",
      "                direction: APtoBP                        \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: xavier                        \n",
      "                 input_nc: 4                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_size: 1024                          \t[default: 286]\n",
      "            mask_modality: segmentation_mask             \n",
      "         max_dataset_size: inf                           \n",
      "                    model: bicycle_gan_hd                \t[default: physics_informed_bicycle_gan]\n",
      "                n_samples: 0                             \t[default: 10]\n",
      "                     name: trial_0                       \t[default: ]\n",
      "                      ndf: 64                            \n",
      "                      nef: 64                            \n",
      "                     netD: basic_1024_multi              \n",
      "                    netD2: basic_1024_multi              \n",
      "                     netE: resnet_1024                   \n",
      "                     netG: global                        \t[default: unet_1024]\n",
      "                      ngf: 48                            \t[default: 64]\n",
      "                       nl: relu                          \n",
      "                no_encode: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: instance                      \n",
      "                   num_Ds: 2                             \n",
      "                 num_test: 387                           \n",
      "              num_threads: 4                             \n",
      "                       nz: 8                             \n",
      "                output_nc: 4                             \n",
      "                    phase: test                          \t[default: val]\n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: temp/BicycleGAN-HD            \t[default: ../results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                     sync: False                         \n",
      "                 upsample: basic                         \n",
      "              use_dropout: False                         \n",
      "                  verbose: False                         \n",
      "                where_add: all                           \n",
      "----------------- End -------------------\n",
      "===== test ./xBD/test_AB/ ./xBD/test_mask\n",
      "dir_AB: ./xBD/test_AB/, dir_A: ./xBD/test_A/, dir_B: ./xBD/test_B/, dir_P_pre: ./xBD/test_mask/, dir_P_post: ./xBD/test_mask/. [dir_AP could be the same as             dir_BP if no pre and post masks available (as it is as of now): ./xBD/test_mask/\n",
      "./xBD/test_mask/\n",
      "Successfully read images and physics related segmentation masks  ./xBD/test_AB/ ./xBD/test_mask/ ./xBD/test_mask/\n",
      "but while data is ready, it is for now:  ./xBD/test_mask/ inf\n",
      "dataset [PhysicsAlignedBinDataset] was created\n",
      "=================\n",
      " BiCycleGANHDModel started... Using conditional_D (for channels): True 4 4\n",
      "GlobalGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(12, 48, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (14): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (15): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (16): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (17): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (18): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (19): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (20): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (21): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (22): ConvTranspose2d(384, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (23): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): ConvTranspose2d(192, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (26): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): ConvTranspose2d(96, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (29): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (30): ReLU(inplace=True)\n",
      "    (31): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (32): Conv2d(48, 4, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (33): Tanh()\n",
      "  )\n",
      ")\n",
      "++++  D_output_nc:  8\n",
      "+++++++++ netE:  4 8\n",
      "+++++++++ E_ResNet: input and output channels, ndf  4 8 64\n",
      "initialize network with xavier\n",
      "model [BicycleGANHDModel] was created\n",
      "loading the model from temp/checkpoint/BicycleGAN-HD/trial_0/latest_net_G.pth\n",
      "loading the model from temp/checkpoint/BicycleGAN-HD/trial_0/latest_net_E.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 25.675 M\n",
      "[Network E] Total number of parameters : 5.083 M\n",
      "-----------------------------------------------\n",
      "Loading model bicycle_gan_hd\n",
      "process input image 000/387\n",
      "process input image 001/387\n",
      "process input image 002/387\n",
      "process input image 003/387\n",
      "process input image 004/387\n",
      "process input image 005/387\n",
      "process input image 006/387\n",
      "process input image 007/387\n",
      "process input image 008/387\n",
      "process input image 009/387\n",
      "process input image 010/387\n",
      "process input image 011/387\n",
      "process input image 012/387\n",
      "process input image 013/387\n",
      "process input image 014/387\n",
      "process input image 015/387\n",
      "process input image 016/387\n",
      "process input image 017/387\n",
      "process input image 018/387\n",
      "process input image 019/387\n",
      "process input image 020/387\n",
      "process input image 021/387\n",
      "process input image 022/387\n",
      "process input image 023/387\n",
      "process input image 024/387\n",
      "process input image 025/387\n",
      "process input image 026/387\n",
      "process input image 027/387\n",
      "process input image 028/387\n",
      "process input image 029/387\n",
      "process input image 030/387\n",
      "process input image 031/387\n",
      "process input image 032/387\n",
      "process input image 033/387\n",
      "process input image 034/387\n",
      "process input image 035/387\n",
      "process input image 036/387\n",
      "process input image 037/387\n",
      "process input image 038/387\n",
      "process input image 039/387\n",
      "process input image 040/387\n",
      "process input image 041/387\n",
      "process input image 042/387\n",
      "process input image 043/387\n",
      "process input image 044/387\n",
      "process input image 045/387\n",
      "process input image 046/387\n",
      "process input image 047/387\n",
      "process input image 048/387\n",
      "process input image 049/387\n",
      "process input image 050/387\n",
      "process input image 051/387\n",
      "process input image 052/387\n",
      "process input image 053/387\n",
      "process input image 054/387\n",
      "process input image 055/387\n",
      "process input image 056/387\n",
      "process input image 057/387\n",
      "process input image 058/387\n",
      "process input image 059/387\n",
      "process input image 060/387\n",
      "process input image 061/387\n",
      "process input image 062/387\n",
      "process input image 063/387\n",
      "process input image 064/387\n",
      "process input image 065/387\n",
      "process input image 066/387\n",
      "process input image 067/387\n",
      "process input image 068/387\n",
      "process input image 069/387\n",
      "process input image 070/387\n",
      "process input image 071/387\n",
      "process input image 072/387\n",
      "process input image 073/387\n",
      "process input image 074/387\n",
      "process input image 075/387\n",
      "process input image 076/387\n",
      "process input image 077/387\n",
      "process input image 078/387\n",
      "process input image 079/387\n",
      "process input image 080/387\n",
      "process input image 081/387\n",
      "process input image 082/387\n",
      "process input image 083/387\n",
      "process input image 084/387\n",
      "process input image 085/387\n",
      "process input image 086/387\n",
      "process input image 087/387\n",
      "process input image 088/387\n",
      "process input image 089/387\n",
      "process input image 090/387\n",
      "process input image 091/387\n",
      "process input image 092/387\n",
      "process input image 093/387\n",
      "process input image 094/387\n",
      "process input image 095/387\n",
      "process input image 096/387\n",
      "process input image 097/387\n",
      "process input image 098/387\n",
      "process input image 099/387\n",
      "process input image 100/387\n",
      "process input image 101/387\n",
      "process input image 102/387\n",
      "process input image 103/387\n",
      "process input image 104/387\n",
      "process input image 105/387\n",
      "process input image 106/387\n",
      "process input image 107/387\n",
      "process input image 108/387\n",
      "process input image 109/387\n",
      "process input image 110/387\n",
      "process input image 111/387\n",
      "process input image 112/387\n",
      "process input image 113/387\n",
      "process input image 114/387\n",
      "process input image 115/387\n",
      "process input image 116/387\n",
      "process input image 117/387\n",
      "process input image 118/387\n",
      "process input image 119/387\n",
      "process input image 120/387\n",
      "process input image 121/387\n",
      "process input image 122/387\n",
      "process input image 123/387\n",
      "process input image 124/387\n",
      "process input image 125/387\n",
      "process input image 126/387\n",
      "process input image 127/387\n",
      "process input image 128/387\n",
      "process input image 129/387\n",
      "process input image 130/387\n",
      "process input image 131/387\n",
      "process input image 132/387\n",
      "process input image 133/387\n",
      "process input image 134/387\n",
      "process input image 135/387\n",
      "process input image 136/387\n",
      "process input image 137/387\n",
      "process input image 138/387\n",
      "process input image 139/387\n",
      "process input image 140/387\n",
      "process input image 141/387\n",
      "process input image 142/387\n",
      "process input image 143/387\n",
      "process input image 144/387\n",
      "process input image 145/387\n",
      "process input image 146/387\n",
      "process input image 147/387\n",
      "process input image 148/387\n",
      "process input image 149/387\n",
      "process input image 150/387\n",
      "process input image 151/387\n",
      "process input image 152/387\n",
      "process input image 153/387\n",
      "process input image 154/387\n",
      "process input image 155/387\n",
      "process input image 156/387\n",
      "process input image 157/387\n",
      "process input image 158/387\n",
      "process input image 159/387\n",
      "process input image 160/387\n",
      "process input image 161/387\n",
      "process input image 162/387\n",
      "process input image 163/387\n",
      "process input image 164/387\n",
      "process input image 165/387\n",
      "process input image 166/387\n",
      "process input image 167/387\n",
      "process input image 168/387\n",
      "process input image 169/387\n",
      "process input image 170/387\n",
      "process input image 171/387\n",
      "process input image 172/387\n",
      "process input image 173/387\n",
      "process input image 174/387\n",
      "process input image 175/387\n",
      "process input image 176/387\n",
      "process input image 177/387\n",
      "process input image 178/387\n",
      "process input image 179/387\n",
      "process input image 180/387\n",
      "process input image 181/387\n",
      "process input image 182/387\n",
      "process input image 183/387\n",
      "process input image 184/387\n",
      "process input image 185/387\n",
      "process input image 186/387\n",
      "process input image 187/387\n",
      "process input image 188/387\n",
      "process input image 189/387\n",
      "process input image 190/387\n",
      "process input image 191/387\n",
      "process input image 192/387\n",
      "process input image 193/387\n",
      "process input image 194/387\n",
      "process input image 195/387\n",
      "process input image 196/387\n",
      "process input image 197/387\n",
      "process input image 198/387\n",
      "process input image 199/387\n",
      "process input image 200/387\n",
      "process input image 201/387\n",
      "process input image 202/387\n",
      "process input image 203/387\n",
      "process input image 204/387\n",
      "process input image 205/387\n",
      "process input image 206/387\n",
      "process input image 207/387\n",
      "process input image 208/387\n",
      "process input image 209/387\n",
      "process input image 210/387\n",
      "process input image 211/387\n",
      "process input image 212/387\n",
      "process input image 213/387\n",
      "process input image 214/387\n",
      "process input image 215/387\n",
      "process input image 216/387\n",
      "process input image 217/387\n",
      "process input image 218/387\n",
      "process input image 219/387\n",
      "process input image 220/387\n",
      "process input image 221/387\n",
      "process input image 222/387\n",
      "process input image 223/387\n",
      "process input image 224/387\n",
      "process input image 225/387\n",
      "process input image 226/387\n",
      "process input image 227/387\n",
      "process input image 228/387\n",
      "process input image 229/387\n",
      "process input image 230/387\n",
      "process input image 231/387\n",
      "process input image 232/387\n",
      "process input image 233/387\n",
      "process input image 234/387\n",
      "process input image 235/387\n",
      "process input image 236/387\n",
      "process input image 237/387\n",
      "process input image 238/387\n",
      "process input image 239/387\n",
      "process input image 240/387\n",
      "process input image 241/387\n",
      "process input image 242/387\n",
      "process input image 243/387\n",
      "process input image 244/387\n",
      "process input image 245/387\n",
      "process input image 246/387\n",
      "process input image 247/387\n",
      "process input image 248/387\n",
      "process input image 249/387\n",
      "process input image 250/387\n",
      "process input image 251/387\n",
      "process input image 252/387\n",
      "process input image 253/387\n",
      "process input image 254/387\n",
      "process input image 255/387\n",
      "process input image 256/387\n",
      "process input image 257/387\n",
      "process input image 258/387\n",
      "process input image 259/387\n",
      "process input image 260/387\n",
      "process input image 261/387\n",
      "process input image 262/387\n",
      "process input image 263/387\n",
      "process input image 264/387\n",
      "process input image 265/387\n",
      "process input image 266/387\n",
      "process input image 267/387\n",
      "process input image 268/387\n",
      "process input image 269/387\n",
      "process input image 270/387\n",
      "process input image 271/387\n",
      "process input image 272/387\n",
      "process input image 273/387\n",
      "process input image 274/387\n",
      "process input image 275/387\n",
      "process input image 276/387\n",
      "process input image 277/387\n",
      "process input image 278/387\n",
      "process input image 279/387\n",
      "process input image 280/387\n",
      "process input image 281/387\n",
      "process input image 282/387\n",
      "process input image 283/387\n",
      "process input image 284/387\n",
      "process input image 285/387\n",
      "process input image 286/387\n",
      "process input image 287/387\n",
      "process input image 288/387\n",
      "process input image 289/387\n",
      "process input image 290/387\n",
      "process input image 291/387\n",
      "process input image 292/387\n",
      "process input image 293/387\n",
      "process input image 294/387\n",
      "process input image 295/387\n",
      "process input image 296/387\n",
      "process input image 297/387\n",
      "process input image 298/387\n",
      "process input image 299/387\n",
      "process input image 300/387\n",
      "process input image 301/387\n",
      "process input image 302/387\n",
      "process input image 303/387\n",
      "process input image 304/387\n",
      "process input image 305/387\n",
      "process input image 306/387\n",
      "process input image 307/387\n",
      "process input image 308/387\n",
      "process input image 309/387\n",
      "process input image 310/387\n",
      "process input image 311/387\n",
      "process input image 312/387\n",
      "process input image 313/387\n",
      "process input image 314/387\n",
      "process input image 315/387\n",
      "process input image 316/387\n",
      "process input image 317/387\n",
      "process input image 318/387\n",
      "process input image 319/387\n",
      "process input image 320/387\n",
      "process input image 321/387\n",
      "process input image 322/387\n",
      "process input image 323/387\n",
      "process input image 324/387\n",
      "process input image 325/387\n",
      "process input image 326/387\n",
      "process input image 327/387\n",
      "process input image 328/387\n",
      "process input image 329/387\n",
      "process input image 330/387\n",
      "process input image 331/387\n",
      "process input image 332/387\n",
      "process input image 333/387\n",
      "process input image 334/387\n",
      "process input image 335/387\n",
      "process input image 336/387\n",
      "process input image 337/387\n",
      "process input image 338/387\n",
      "process input image 339/387\n",
      "process input image 340/387\n",
      "process input image 341/387\n",
      "process input image 342/387\n",
      "process input image 343/387\n",
      "process input image 344/387\n",
      "process input image 345/387\n",
      "process input image 346/387\n",
      "process input image 347/387\n",
      "process input image 348/387\n",
      "process input image 349/387\n",
      "process input image 350/387\n",
      "process input image 351/387\n",
      "process input image 352/387\n",
      "process input image 353/387\n",
      "process input image 354/387\n",
      "process input image 355/387\n",
      "process input image 356/387\n",
      "process input image 357/387\n",
      "process input image 358/387\n",
      "process input image 359/387\n",
      "process input image 360/387\n",
      "process input image 361/387\n",
      "process input image 362/387\n",
      "process input image 363/387\n",
      "process input image 364/387\n",
      "process input image 365/387\n",
      "process input image 366/387\n",
      "process input image 367/387\n",
      "process input image 368/387\n",
      "process input image 369/387\n",
      "process input image 370/387\n",
      "process input image 371/387\n",
      "process input image 372/387\n",
      "process input image 373/387\n",
      "process input image 374/387\n",
      "process input image 375/387\n",
      "process input image 376/387\n",
      "process input image 377/387\n",
      "process input image 378/387\n",
      "process input image 379/387\n",
      "process input image 380/387\n",
      "process input image 381/387\n",
      "process input image 382/387\n",
      "process input image 383/387\n",
      "process input image 384/387\n",
      "process input image 385/387\n",
      "process input image 386/387\n"
     ]
    }
   ],
   "source": [
    "!cd ../.. ; python src/models/BicycleGAN-HD/test.py --ngf 48 --phase test --num_test 387 --n_samples 0 --results_dir temp/BicycleGAN-HD --model bicycle_gan_hd --checkpoints_dir temp/checkpoint/BicycleGAN-HD/ --name trial_0 --gpu_ids -1 --direction APtoBP --dataset_mode physics_aligned_bin --dataroot ./xBD/ --load_size 1024 --crop_size 1024 --batch_size 2 --dataroot_A_masks ./xBD/test_mask --dataroot_B_masks ./xBD/test_mask --netD basic_1024_multi --netD2 basic_1024_multi --netG global --netE resnet_1024 --conditional_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘to_segment’: File exists\n",
      "cp: cannot stat 'images/*synthesized.png': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Move synthesized results to a folder to be used by the segmentation network\n",
    "!cd ../../temp/BicycleGAN-HD/test/ ; mkdir to_segment; cp -R images/*synthesized.png to_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./pretrained/Pix2pix-CycleGAN/flood_segmentation/scratch_1024_plus/\t[default: ./checkpoints]\n",
      "                crop_size: 1024                          \t[default: 256]\n",
      "                 dataroot: temp/BicycleGAN-HD/test/to_segment/\t[default: None]\n",
      "             dataset_mode: single                        \t[default: aligned]\n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "               isFineTune: False                         \t[default: None]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 1024                          \t[default: 256]\n",
      "         max_dataset_size: 2000                          \t[default: inf]\n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: .                             \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: True                          \t[default: False]\n",
      "                     norm: batch                         \n",
      "                 num_test: 10000                         \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: to_segment                    \t[default: test]\n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./temp/BicycleGAN-HD/trial_0_masks\t[default: ./results/]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./pretrained/Pix2pix-CycleGAN/flood_segmentation/scratch_1024_plus/./latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./temp/BicycleGAN-HD/trial_0_masks/./to_segment_latest\n",
      "Traceback (most recent call last):\n",
      "  File \"src/models/Pix2pix-CycleGAN/test.py\", line 79, in <module>\n",
      "    with open(csv_path, 'w') as losses_csv:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './temp/BicycleGAN-HD/trial_0_masks./loses.csv'\n"
     ]
    }
   ],
   "source": [
    "#Create Segmentation Masks\n",
    "#Generate masks for all of the data generated by pix2pixHD_baseline\n",
    "! cd ../.. ; python src/models/Pix2pix-CycleGAN/test.py --phase to_segment --dataroot temp/BicycleGAN-HD/test/to_segment/ --direction AtoB --results_dir ./temp/BicycleGAN-HD/trial_0_masks --dataset_mode single --model pix2pix --checkpoints_dir ./pretrained/Pix2pix-CycleGAN/flood_segmentation/scratch_1024_plus/ --name . --num_test 10000 --no_flip --gpu_ids -1 --max_dataset_size 2000 --batch_size 1  --load_size 1024 --crop_size 1024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we copy our generated images into the right ./Results/. directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ../.. ; mkdir results/BicycleGAN-HD/trial_0_global_gen/; cp -R temp/BicycleGAN-HD/test/images/* results/BicycleGAN-HD/trial_0_global_gen/ ; cp -R temp/BicycleGAN-HD/trial_0_masks/to_segment_latest/images/*synthesized_fake_B.png results/BicycleGAN-HD/trial_0_global_gen/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
